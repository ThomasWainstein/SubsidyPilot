name: FranceAgriMer Subsidy Scraper

on:
  # Weekly schedule: Every Sunday at 01:00 UTC
  schedule:
    - cron: '0 1 * * 0'
  
  # Manual trigger for immediate execution
  workflow_dispatch:
    inputs:
      max_pages:
        description: 'Maximum pages to scrape (0 = unlimited)'
        required: false
        default: '0'
        type: string
      dry_run:
        description: 'Dry run mode (no database writes)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      force_purge:
        description: 'Force contamination purge (removes all non-FranceAgriMer artifacts)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

jobs:
  scrape-franceagrimer:
    runs-on: ubuntu-latest

env:
  SUPABASE_URL: https://gvfgvbztagafjykncwto.supabase.co
  SUPABASE_SERVICE_KEY: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imd2Zmd2Ynp0YWdhZmp5a25jd3RvIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0ODcwODE3MywiZXhwIjoyMDY0Mjg0MTczfQ.j3KEkFJLrDKbmyCHPPHW67zjzMlua4Gff4hzvqW_LZY

    
    steps:
      - name: Print runner/system context
        run: |
          echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
          echo "RUNNER_OS: $RUNNER_OS"
          echo "HOSTNAME: $(hostname)"
          lsb_release -a || true
          env | sort
          df -h
          free -h
          which python3
          python3 --version
          pip --version

      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            chromium-browser \
            chromium-chromedriver \
            python3-pip \
            python3-venv
            
      - name: Install Python dependencies
        working-directory: ./AgriToolScraper-main
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Configure Chrome for headless operation
        run: |
          export CHROME_BIN=/usr/bin/chromium-browser
          export CHROMEDRIVER_BIN=/usr/bin/chromedriver
          
      - name: Set up environment variables
        run: |
          echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
          echo "SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" >> $GITHUB_ENV
          echo "CHROME_BIN=/usr/bin/chromium-browser" >> $GITHUB_ENV
          echo "CHROMEDRIVER_BIN=/usr/bin/chromedriver" >> $GITHUB_ENV
          echo "FORCE_PURGE=${{ github.event.inputs.force_purge || 'false' }}" >> $GITHUB_ENV
          
      - name: üî• STEP 1 - SELENIUM 4+ COMPLIANCE VALIDATION
        working-directory: ./AgriToolScraper-main  
        run: |
          echo "üî• SELENIUM 4+ COMPLIANCE VALIDATION (AST-ONLY)"
          echo "üîç SCANNING EXECUTABLE CODE FOR SELENIUM VIOLATIONS"
          python selenium_compliance_validator.py || (
            echo "‚ùå SELENIUM 4+ COMPLIANCE FAILED - VIOLATIONS DETECTED"
            echo "‚ùå SCRAPER EXECUTION BLOCKED"
            echo "‚ùå Review SELENIUM_4_COMPLIANCE_ENFORCEMENT.md"
            echo "‚ùå Fix all violations before re-running"
            exit 1
          )
          echo "‚úÖ SELENIUM 4+ COMPLIANCE VERIFIED - ZERO VIOLATIONS"
          echo "‚úÖ Proceeding with enhanced scraper pipeline"

      - name: üîÑ STEP 2 - CACHE CLEARING & CONDITIONAL PURGE
        working-directory: ./AgriToolScraper-main
        env:
          FORCE_PURGE: ${{ github.event.inputs.force_purge || 'false' }}
        run: |
          echo "üîÑ STEP 2A - CLEARING PYTHON RUNTIME CACHES"
          python clear_cache.py
          
          echo "üîÑ STEP 2B - CONDITIONAL CONTAMINATION PURGE"
          if [ "$FORCE_PURGE" = "true" ]; then
            echo "üßπ FORCE_PURGE=true - Running full contamination purge"
            python purge_contamination.py
          else
            echo "‚ÑπÔ∏è FORCE_PURGE not set - Skipping contamination purge"
            echo "üí° Use FORCE_PURGE=true in workflow inputs to enable"
          fi
          echo "‚úÖ STEP 2 COMPLETE"

      - name: üöó STEP 3 - DRIVER COMPLIANCE TEST
        working-directory: ./AgriToolScraper-main
        run: |
          echo "üöó TESTING DRIVER COMPLIANCE AND INITIALIZATION"
          echo "üîç ENSURING SELENIUM 4+ DRIVERS WORK CORRECTLY"
          python test_driver_compliance.py
          echo "‚úÖ DRIVER COMPLIANCE VERIFIED"

      - name: üá´üá∑ STEP 4 - FRANCEAGRIMER SCRAPER EXECUTION
        working-directory: ./AgriToolScraper-main
        run: |
          echo "üá´üá∑ EXECUTING FRANCEAGRIMER SUBSIDY SCRAPER"
          echo "üéØ TARGET: https://www.franceagrimer.fr/Accompagner/Dispositifs-par-filiere/Aides-nationales"
          echo "üìÑ MAX_PAGES: ${{ github.event.inputs.max_pages || '0' }}"
          echo "üî• DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}"
          echo "üßπ FORCE_PURGE: ${{ github.event.inputs.force_purge || 'false' }}"
          
          python main.py \
            --url "https://www.franceagrimer.fr/Accompagner/Dispositifs-par-filiere/Aides-nationales" \
            --max-pages "${{ github.event.inputs.max_pages || '0' }}" \
            --dry-run="${{ github.event.inputs.dry_run || 'false' }}"
          
          echo "‚úÖ FRANCEAGRIMER SCRAPER COMPLETED SUCCESSFULLY"
            
      - name: üì¶ Upload logs and extracted data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: franceagrimer-scraper-output
          path: |
            AgriToolScraper-main/data/extracted/franceagrimer_*
            AgriToolScraper-main/data/logs/franceagrimer_*
            AgriToolScraper-main/job_execution_log.json
            AgriToolScraper-main/*.log
          retention-days: 30
          
      - name: Upload FranceAgriMer error screenshots  
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: franceagrimer-errors-${{ github.run_number }}
          path: |
            AgriToolScraper-main/data/extracted/franceagrimer_screenshots_*
            AgriToolScraper-main/data/logs/franceagrimer_*error*.png
          retention-days: 7
          
      - name: Print debug information on failure
        if: failure()
        run: |
          echo "===== DEBUG INFORMATION ====="
          echo "Working directory structure:"
          find AgriToolScraper-main/ -type f -name "*.log" || true
          find AgriToolScraper-main/data/ || true
          echo "===== LOG TAILS (last 50 lines each) ====="
          tail -n 50 AgriToolScraper-main/*.log || true
          tail -n 50 AgriToolScraper-main/data/logs/*.log || true
          tail -n 50 AgriToolScraper-main/data/extracted/*.log || true

      - name: ‚úÖ SUCCESS NOTIFICATION
        if: success()
        run: |
          echo "üéâ FRANCEAGRIMER SCRAPER JOB COMPLETED SUCCESSFULLY"
          echo "="*60
          echo "üìä EXECUTION SUMMARY:"
          echo "   - Selenium 4+ Compliance: ‚úÖ VERIFIED" 
          echo "   - Cache Clearing: ‚úÖ COMPLETED"
          echo "   - Contamination Purge: ‚úÖ CONDITIONAL"
          echo "   - Driver Initialization: ‚úÖ TESTED"
          echo "   - FranceAgriMer Scraping: ‚úÖ COMPLETED"
          echo "="*60
          echo "üìÅ ARTIFACTS UPLOADED:"
          echo "   - FranceAgriMer logs and results"
          echo "   - Error screenshots (if any)"
          echo "   - Raw extracted data"
          echo "="*60
          echo "üöÄ JOB STATUS: SUCCESS - READY FOR PRODUCTION"

      - name: ‚ùå FAILURE NOTIFICATION  
        if: failure()
        run: |
          echo "üí• FRANCEAGRIMER SCRAPER JOB FAILED"
          echo "="*60
          echo "‚ùå FAILURE ANALYSIS REQUIRED"
          echo "üìã CHECK THE FOLLOWING:"
          echo "   1. Selenium 4+ compliance violations"
          echo "   2. Driver initialization issues"
          echo "   3. Website structure changes"
          echo "   4. Network connectivity problems"
          echo "   5. Supabase credentials/permissions"
          echo "="*60
          echo "üìÅ DEBUG ARTIFACTS UPLOADED FOR ANALYSIS"
          echo "üîß FIX ISSUES BEFORE RETRY"
