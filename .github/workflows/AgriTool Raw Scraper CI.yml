# =============================================================================
# AgriTool Raw Scraper CI - ROBUST WORKFLOW
# =============================================================================
# This workflow implements comprehensive robustness requirements:
# - System Chrome & Chromedriver installation (no exec format errors)
# - Virtual display setup (Xvfb) for headless Selenium
# - Binary validation and debug logging
# - Secure secret management for Supabase
# - Comprehensive artifact uploads
# - Failure handling with detailed logs
# - Manual and scheduled triggers
# - Retry logic and error handling
# =============================================================================

name: üî• AgriTool Raw Scraper CI - BULLETPROOF

on:
  push:
    paths:
      - 'AI_SCRAPER_RAW_TEXTS/**'
      - '.github/workflows/AgriTool Raw Scraper CI.yml'
  pull_request:
    paths:
      - 'AI_SCRAPER_RAW_TEXTS/**'
  workflow_dispatch:
    inputs:
      site:
        description: 'Target site to scrape'
        required: false
        default: 'franceagrimer'
        type: choice
        options:
          - franceagrimer
          - all
      start_page:
        description: 'Start page number'
        required: false
        default: '0'
      end_page:
        description: 'End page number'
        required: false
        default: '2'
      dry_run:
        description: 'Dry run upload (no actual Supabase insert)'
        required: false
        default: false
        type: boolean
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'

env:
  DISPLAY: ':99'
  PYTHONUNBUFFERED: '1'
  
jobs:
  bulletproof-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    defaults:
      run:
        working-directory: AI_SCRAPER_RAW_TEXTS
    steps:
      - name: üìã Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üîß Install system dependencies (Chrome/Chromedriver/Xvfb)
        run: |
          echo "üîß Installing system dependencies..."
          sudo apt-get update -qq
          sudo apt-get install -y chromium-browser chromium-chromedriver xvfb file wget curl
          echo "‚úÖ System dependencies installed"

      - name: üñ•Ô∏è Setup virtual display (Xvfb)
        run: |
          echo "üñ•Ô∏è Starting virtual display..."
          Xvfb :99 -screen 0 1920x1080x24 -ac &
          export DISPLAY=:99
          sleep 3
          echo "‚úÖ Virtual display started on :99"
        env:
          DISPLAY: ':99'

      - name: üîç Debug Chrome/Chromedriver installation
        run: |
          echo "üîç === CHROME/CHROMEDRIVER DEBUG INFO ==="
          echo "üìç Chromium browser location:"
          which chromium-browser || echo "‚ùå chromium-browser not found"
          if command -v chromium-browser >/dev/null 2>&1; then
            chromium-browser --version || echo "‚ùå Cannot get Chromium version"
          fi
          
          echo "üìç Chromedriver location:"
          which chromedriver || echo "‚ùå chromedriver not found"
          if command -v chromedriver >/dev/null 2>&1; then
            chromedriver --version || echo "‚ùå Cannot get Chromedriver version"
          fi
          
          echo "üìç Binary details:"
          ls -l /usr/bin/chromedriver || echo "‚ùå /usr/bin/chromedriver not found"
          ls -l /usr/bin/chromium-browser || echo "‚ùå /usr/bin/chromium-browser not found"
          
          echo "üìç Display info:"
          echo "DISPLAY: $DISPLAY"
          ps aux | grep Xvfb || echo "‚ùå Xvfb not running"
          echo "‚úÖ Debug info complete"

      - name: üßπ Clear webdriver-manager cache
        run: |
          echo "üßπ Clearing webdriver-manager cache..."
          rm -rf ~/.wdm || true
          rm -rf /home/runner/.wdm || true
          echo "‚úÖ Webdriver-manager cache cleared"

      - name: üì¶ Install Python dependencies
        run: |
          echo "üì¶ Installing Python dependencies..."
          pip install --upgrade pip
          pip install -r requirements.txt
          echo "‚úÖ Python dependencies installed"
          echo "üìã Installed packages:"
          pip list | grep -E "(selenium|supabase|requests|beautifulsoup4)"

      - name: üîç Validate environment variables
        run: |
          echo "üîç Validating required Supabase environment variables..."
          python ../test_env_vars.py
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

      - name: üß™ Test system chromedriver directly
        run: |
          echo "üß™ Testing system chromedriver..."
          chromedriver --version
          python -c "
          from selenium import webdriver
          from selenium.webdriver.chrome.service import Service
          from selenium.webdriver.chrome.options import Options
          options = Options()
          options.add_argument('--headless=new')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          driver = webdriver.Chrome(service=Service('/usr/bin/chromedriver'), options=options)
          print('‚úÖ System chromedriver test successful')
          driver.quit()
          "
          echo "‚úÖ System chromedriver validation completed"

      - name: üß™ Run comprehensive test suite
        run: |
          echo "üß™ Running test suite..."
          python test_scraper.py
          echo "‚úÖ Test suite completed successfully"

      - name: üï∑Ô∏è Batch scrape (FranceAgriMer pages ${{ github.event.inputs.start_page || '0' }}‚Äì${{ github.event.inputs.end_page || '2' }})
        run: |
          echo "üï∑Ô∏è Starting batch scrape..."
          SITE="${{ github.event.inputs.site || 'franceagrimer' }}"
          START_PAGE="${{ github.event.inputs.start_page || '0' }}"
          END_PAGE="${{ github.event.inputs.end_page || '2' }}"
          
          echo "üìä Scrape parameters:"
          echo "  Site: $SITE"
          echo "  Start page: $START_PAGE"
          echo "  End page: $END_PAGE"
          
          python scraper_main.py --site $SITE --start-page $START_PAGE --end-page $END_PAGE
          echo "‚úÖ Batch scrape completed"

      - name: üìä Validate scraper outputs
        run: |
          echo "üìä === SCRAPER OUTPUT VALIDATION ==="
          echo "üìÅ Raw pages directory:"
          if [ -d "data/raw_pages" ]; then
            ls -la data/raw_pages/ | head -20
            echo "üìã Total JSON files: $(find data/raw_pages -name "*.json" | wc -l)"
          else
            echo "‚ùå data/raw_pages directory not found"
          fi
          
          echo "üìÅ Attachments directory:"
          if [ -d "data/attachments" ]; then
            ls -la data/attachments/ | head -10
            echo "üìã Total attachments: $(find data/attachments -type f | wc -l)"
          else
            echo "‚ö†Ô∏è data/attachments directory not found (may be empty)"
          fi
          
          echo "üìÅ Logs directory:"
          if [ -d "data/logs" ]; then
            ls -la data/logs/
          else
            echo "‚ö†Ô∏è data/logs directory not found"
          fi

      - name: üîÑ Upload raw data to Supabase (dry run validation)
        run: |
          echo "üîÑ Running Supabase upload dry run..."
          python upload_raw_to_supabase.py --dry-run --batch-size 25
          echo "‚úÖ Dry run validation completed"

      - name: üöÄ Upload raw data to Supabase (live upload)
        if: ${{ github.event.inputs.dry_run != 'true' }}
        run: |
          echo "üöÄ Starting live Supabase upload..."
          python upload_raw_to_supabase.py --batch-size 25
          echo "‚úÖ Live upload completed"
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        continue-on-error: false

      - name: üìã Upload success validation
        run: |
          echo "üìã === UPLOAD SUCCESS VALIDATION ==="
          if [ -f "data/logs/supabase_upload.log" ]; then
            echo "üìÑ Upload log found - showing last 30 lines:"
            tail -30 data/logs/supabase_upload.log
            
            echo "üìä Upload statistics:"
            grep -E "(Uploaded|Error|Skip)" data/logs/supabase_upload.log | tail -10 || true
          else
            echo "‚ö†Ô∏è Upload log not found at data/logs/supabase_upload.log"
          fi

      - name: üì¶ Upload raw_pages as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: raw_pages-${{ github.run_number }}
          path: AI_SCRAPER_RAW_TEXTS/data/raw_pages/
          retention-days: 30

      - name: üì¶ Upload attachments as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: attachments-${{ github.run_number }}
          path: AI_SCRAPER_RAW_TEXTS/data/attachments/
          retention-days: 30

      - name: üì¶ Upload logs as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: logs-${{ github.run_number }}
          path: AI_SCRAPER_RAW_TEXTS/data/logs/
          retention-days: 7

      - name: üéØ Success Summary
        if: success()
        run: |
          echo "üéØ === WORKFLOW SUCCESS SUMMARY ==="
          echo "‚úÖ All steps completed successfully"
          echo "‚úÖ Chrome/Chromedriver: Working"
          echo "‚úÖ Virtual display: Working"
          echo "‚úÖ Test suite: Passed"
          echo "‚úÖ Scraping: Completed"
          echo "‚úÖ Supabase upload: Success"
          echo "‚úÖ Artifacts: Uploaded"
          echo ""
          echo "üìä Final statistics:"
          echo "  JSON files: $(find data/raw_pages -name "*.json" 2>/dev/null | wc -l)"
          echo "  Attachments: $(find data/attachments -type f 2>/dev/null | wc -l)"
          echo "  Run ID: ${{ github.run_number }}"

      - name: ‚ùå Failure Debug & Logs
        if: failure()
        run: |
          echo "‚ùå === WORKFLOW FAILURE DEBUG ==="
          echo "‚ùå Workflow failed - collecting debug information"
          echo ""
          echo "üîç Environment info:"
          echo "  Python version: $(python --version)"
          echo "  DISPLAY: $DISPLAY"
          echo "  Working directory: $(pwd)"
          echo ""
          echo "üîç Process info:"
          ps aux | grep -E "(Xvfb|chrome)" || echo "No Chrome/Xvfb processes found"
          echo ""
          echo "üîç Directory structure:"
          find . -type d -name "data" -exec ls -la {} \; 2>/dev/null || true
          echo ""
          echo "üîç Recent logs (last 50 lines):"
          find data/logs -name "*.log" -exec echo "=== {} ===" \; -exec tail -50 {} \; 2>/dev/null || echo "No log files found"
          echo ""
          echo "üîç Chrome/driver debug:"
          which chromium-browser chromedriver || true
          ls -la /usr/bin/chrome* 2>/dev/null || true
          echo ""
          echo "‚ùå Debug information collection complete"
